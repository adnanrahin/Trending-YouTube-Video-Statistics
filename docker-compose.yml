version: "3.7"
services:
  spark-master:
    build:
      context: .                          #docker file path (. means root directory)
      dockerfile: Dockerfile
    image: cluster-apache-spark:3.1.2
    ports:
      - "9090:8080"
      - "7077:7077"
    volumes:
      - ./data-preprocessing-engine/target/:/opt/spark-apps-preprocessing
      - ./data-scoring-processor/target/:/opt/spark-apps-scoring
      - ./data-set:/opt/spark-data
    environment:
      - SPARK_LOCAL_IP=spark-master
      - SPARK_WORKLOAD=master

  spark-worker-a:
    image: cluster-apache-spark:3.1.2
    ports:
      - "9091:8080"
      - "7078:7080"
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=4
      - SPARK_WORKER_MEMORY=2G
      - SPARK_DRIVER_MEMORY=2G
      - SPARK_EXECUTOR_MEMORY=2G
      - SPARK_WORKLOAD=worker
      - SPARK_LOCAL_IP=spark-worker-a
    volumes:
      - ./data-preprocessing-engine/target/:/opt/spark-apps-preprocessing
      - ./data-scoring-processor/target/:/opt/spark-apps-scoring
      - ./data-set:/opt/spark-data
    restart: always

  spark-worker-b:
    image: cluster-apache-spark:3.1.2
    ports:
      - "9092:8080"
      - "7079:7079"
    depends_on:
      - spark-master
    environment:
      - SPARK_MASTER=spark://spark-master:7077
      - SPARK_WORKER_CORES=4
      - SPARK_WORKER_MEMORY=4G
      - SPARK_DRIVER_MEMORY=2G
      - SPARK_EXECUTOR_MEMORY=2G
      - SPARK_WORKLOAD=worker
      - SPARK_LOCAL_IP=spark-worker-b
    volumes:
      - ./data-preprocessing-engine/target/:/opt/spark-apps-preprocessing
      - ./data-scoring-processor/target/:/opt/spark-apps-scoring
      - ./data-set:/opt/spark-data
    restart: always
